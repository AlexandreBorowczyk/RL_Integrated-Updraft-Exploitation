import torch
import torch.nn as nn
from torch.distributions import MultivariateNormal

class ActorCritic(nn.Module):
    """ Class that defines the actor-critic model for the updraft finder

        Attributes
        ----------
        _params_model: ModelParameters
            Shape of the network layers

        _params_rl: LearningParameters
            Hyperparameters for training

        _device : torch.device
            Sets training device (CPU or GPU)

        actor: LSTMActor
            Actor network which has a linear input layer, a LSTM hidden layer and a linear output layer

        critic: Critic
            Critic network with linear input, hidden and output layer
    """

    def __init__(self, params_model, params_rl, device=torch.device("cpu")):
        super().__init__()

        # instantiate parameters
        self._params_model = params_model
        self._params_rl = params_rl
        self._device = device

        # setup ANN
        self.actor = LSTMActor(obs_dim=self._params_model.DIM_IN, act_dim=self._params_model.DIM_OUT,
                               hidden_size=self._params_model.DIM_HIDDEN, lstm_size=self._params_model.DIM_LSTM,
                               device=self._device)
        self.critic = Critic(obs_dim=self._params_model.DIM_IN, hidden_size=self._params_model.DIM_HIDDEN,
                             device=self._device)

    def act(self, state, lstm_hidden, validation_mask=False):
        """ Evaluates current actor model for a given observation. The observation contains aircraft position and
            energy equivalent climb rate

            Parameters
            ----------
            state : Tensor
                Single observation for updraft finder (aircraft position, energy equivalent climb rate)

            lstm_hidden : Tensor
                Previous hidden LSTM state

            validation_mask : bool
                Deactivates random action sampling

            Returns
            -------
            action : Tensor
                Sampled action

            action_logprob : Tensor
                Logarithmic probability of action

            lstm_hidden : Tensor
                New hidden LSTM state
    """

        # evaluate current actor to sample action for rollout
        action_mean, lstm_hidden = self.actor.forward(state, lstm_hidden)
        if not validation_mask:
            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)
            dist = MultivariateNormal(action_mean, covariance_matrix=cov_mat)
            action = dist.sample()
            action_logprob = dist.log_prob(action)
        else:
            action = action_mean
            action_logprob = 0

        return action, action_logprob, lstm_hidden

    def evaluate_actor(self, sampled_state, sampled_action, sampled_lstm_hidden):
        """ Evaluates actor network for sampled inputs during PPO update step

            Parameters
            ----------
            sampled_state : Tensor
                Sampled states from PPO Buffer

            sampled_action : Tensor
                Sampled actions from PPO buffer

            sampled_lstm_hidden : Tensor
                Sampled lstm states from PPO buffer

            Returns
            -------
            flattened_action_logprobs : Tensor
                Logprobs for all sampled actions as a flattened 1D array
        """

        # evaluate actor for sampled states
        action_mean, _ = self.actor.forward(sampled_state, sampled_lstm_hidden)
        action_var = self.action_var.expand_as(action_mean)
        cov_mat = torch.diag_embed(action_var).to(self._device)
        dist = MultivariateNormal(action_mean, cov_mat)

        # get logprobs for distribution subject to current actor, evaluated for sampled actions
        action_logprobs = dist.log_prob(sampled_action)

        return action_logprobs.flatten()

    def reset_lstm(self):
        """ Resets LSTM inital and cell state

            Returns
            -------
            h_0 : Tensor
                Reset initial state of LSTM

            c_0 : Tensor
                Reset cell state of LSTM
        """

        return torch.zeros(1, 1, self._params_model.DIM_LSTM, device=self._device), \
               torch.zeros(1, 1, self._params_model.DIM_LSTM, device=self._device)


class LSTMActor(nn.Module):
    """ This class implements the actor model. It has three layers. Input and output layers are
        simple linear layers. The hidden layer is a Long Short-Term Memory (LSTM) layer

        Attributes
        ----------
        input_layer : torch.nn.Linear
            Linear input layer

        lstm : torch.nn.LSTM
            Hidden LSTM layer

        output_layer : torch.nn.Linear
            Linear output layer

        _obs_dim : object
            Dimension of observation vector

        _act_dim : object
            Dimension of action space

        _hidden_size : object
            Dimension of LSTM input size.

        _lstm_size : object
            Dimension of LSTM layer
        """

    def __init__(self, obs_dim, act_dim, hidden_size, lstm_size, device):
        super().__init__()

        self.input_layer = nn.Linear(obs_dim, hidden_size)
        self.lstm = nn.LSTM(hidden_size, lstm_size)
        self.output_layer = nn.Linear(lstm_size, act_dim)

        self._obs_dim = obs_dim
        self._act_dim = act_dim
        self._hidden_size = hidden_size
        self._lstm_size = lstm_size

        self._device = device

    def forward(self, observation, lstm_hidden):
        """ Computes forward pass through actor network of decision maker. Output is a probability for using the
            updraft exploiter sub-policy

            Parameters
            ----------
            observation : Tensor
                Sequence of observations for updraft finder (aircraft position, energy equivalent climb rate). Sequence
                can have a variable length

            lstm_hidden :
                Previous state of hidden LSTM layer

            Returns
            -------
            action : float
                Probability for updraft exploitation

            lstm_hidden : Tensor
                Internal state of LSTM
        """
        # evaluate input
        x = observation.reshape(-1, self._obs_dim).to(self._device)  # seq_len x  input_size
        x = torch.tanh(self.input_layer(x))

        # evaluate lstm
        x = x.reshape(-1, 1, self._hidden_size)  # seq_len x batch_size x  lstm_in_size
        x, lstm_hidden = self.lstm(x, (lstm_hidden[0].reshape(1, 1, self._hidden_size),
                                       lstm_hidden[1].reshape(1, 1, self._hidden_size)))

        # evaluate actor output layer
        x = x.reshape(-1, self._lstm_size)  # seq_len x lstm_out_size
        action = self.output_layer(x)

        return action, lstm_hidden


class Critic(nn.Module):
    """ This class implements the critic model for the updraft finder.

        Attributes
        ----------
        input_layer : torch.nn.Linear
            Input layer of critic network

        hidden_layer : torch.nn.Linear
            Hidden layer of critic network

        output_layer : torch.nn.Linear
            Output layer of critic network

        _obs_dim : int
            Dimension of input to critic network

       _device : torch.device
            Sets training device (CPU or GPU)

        """

    def __init__(self, obs_dim, hidden_size, device):
        super().__init__()

        self.input_layer = nn.Linear(obs_dim, hidden_size)
        self.hidden_layer = nn.Linear(hidden_size, hidden_size)
        self.output_layer = nn.Linear(hidden_size, 1)

        self._obs_dim = obs_dim

        self._device = device

    def forward(self, observation):
        """ Computes forward pass trough critic network, which puts out the value of the current
            state (observation)

            Parameters
            ----------
            observation : Tensor
                Sequence of observations for updraft finder (aircraft position, energy equivalent climb rate). Sequence
                can have a variable length

            Returns
            -------
            value : float
                State value of observation
        """
        # evaluate input
        x = observation.reshape(-1, self._obs_dim).to(self._device)  # batch_size x  input_size
        x = torch.tanh(self.input_layer(x))

        # evaluate hidden layer
        x = torch.tanh(self.hidden_layer(x))

        # evaluate critic output layer
        value = self.output_layer(x)

        return value
