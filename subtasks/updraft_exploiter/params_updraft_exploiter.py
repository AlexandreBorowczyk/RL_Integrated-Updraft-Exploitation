import numpy as np
from parameters.params_environment import params_glider, params_physics

class params_rl:
    def __init__(self):
        self.N_EPISODES         = 2e3           # total number of episodes to be evaluated
        self.BATCHSIZE          = 4096          # size of bach (i.e, length of rollout) before policy update
        self.SEQ_LEN            = 256           # size of mini-batch for SGD (evaluated as a sequence, due to LSTM)
        self.OVERLAP            = 128           # shift tuples for overlapping sequences (shift = seq_len - overlap)
        self.SEQ_LEN_MIN        = 64            # minimum sequence length to be evaluated (if sliced due to episode end)
        self.N_BURNIN           = 16            # use first steps of each sequence to "burn in" hidden state
        self.K_EPOCH            = 10            # number of policy updates on single batch
        self.LEARNING_RATE_PI   = 5e-5          # learning rate for actor optimizer
        self.LEARNING_RATE_VF   = 1e-4          # learning rate for critic optimizer
        self.GAMMA              = 0.997         # discount factor for advantage estimation
        self.LAMBDA             = 0.96          # only relevant if GAE is implemented
        self.EPS_CLIP           = 0.2           # PPO clipping value
        self.SIGMA              = .2            # std-deviation for exploration (0.1 -> 0.6 deg after scaling)
        self.AUTO_EXPLORATION   = False         # exploration driven by NN output (self.SIGMA obsolete if true)
        self.SEED               = None          # manual specification of random seed (Fabian: 42)


class params_model:
    def __init__(self):
        self.DIM_IN         = 7                 # dimension of observation-space
        self.DIM_OUT        = 1                 # dimension of action-space - for decision maker: prob. for subtask
        self.DIM_HIDDEN     = 32
        self.DIM_LSTM       = 32


class params_agent:
    def __init__(self):
        # instantiate params_glider, params_physics object
        self._params_glider = params_glider()
        self._params_physics = params_physics()

        # control update time-step (s)
        self.TIMESTEP_CRTL = 1.0

        # initial state space [MIN MAX]
        self.INITIAL_SPACE = np.array([[-500, 500],
                                       [-500, 500],
                                       [-405, -395],
                                       [-10, 10],
                                       [-10, 10],
                                       [0.5, 1.5]])

        # bank angle and AoA constraint to [MIN MAX]   (deg)
        self.ACTION_SPACE = np.array([[-45, 45],
                                      [0, 12]])

        # mean values for observation standardization
        V_best, gamma_best = self.get_best_glide()
        self.OBS_MEAN = np.array([0, 0, -200,                   # position: NED
                                  V_best, gamma_best, 0,        # path velocity: V_K, gamma, chi
                                  V_best])                      # speed wrt air  TODO: meaningful, cf. TEK vario!?

        # spread parameters for observation standardization
        self.OBS_STD = np.array([500, 500, 200,
                                  V_best/2, np.deg2rad(15), np.pi,
                                  V_best/2])

        # maximum horizontal distance allowed from origin (ensures that a safety pilot could interact)
        self.DISTANCE_MAX = 1e3

        # maximum height allowed
        self.HEIGHT_MAX = 500

    def get_best_glide(self):
        alpha_bestGlide = ((self._params_glider.ST + 2)
                           * np.sqrt(self._params_glider.CD0*self._params_glider.OE/self._params_glider.ST))\
                           / (2*np.sqrt(np.pi))
        cL_bestGlide = (2*np.pi*alpha_bestGlide*self._params_glider.ST)/(self._params_glider.ST + 2)
        cD_bestGlide = self._params_glider.CD0\
                       + (1 / (np.pi * self._params_glider.ST * self._params_glider.OE)) * np.power(cL_bestGlide, 2)

        V_bestGlide = np.sqrt((2*self._params_glider.M*self._params_physics.G)
                              /(self._params_physics.RHO*self._params_glider.S*cL_bestGlide))
        gamma_bestGlide = -cD_bestGlide / cL_bestGlide

        return V_bestGlide, gamma_bestGlide


class params_logging:
    def __init__(self):
        self.PRINT_INTERVAL = 10  # interval wrt # epi to print score and save avg. return to file
        self.SAVE_INTERVAL = 50  # interval wrt # epi to save actor/critic net and make a plot
